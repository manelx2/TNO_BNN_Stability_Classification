{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "995b228d",
   "metadata": {},
   "source": [
    "My goal with this jupiter note book is to combine all my work and add the latest asked changes to collect the std and moy for each predicted sample using MC dropout BNN aproximation and Bayes by back propagation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3734d5cc",
   "metadata": {},
   "source": [
    "LOAD DATA: I am loading the same dataset that I will be using for training both models later, which was before collected using revound simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46c8c7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_32316\\3582689913.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_32316\\3582689913.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train_tensor = torch.tensor(y_train, dtype=torch.long)  # long for classification\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_32316\\3582689913.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_32316\\3582689913.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Load CSV\n",
    "def load_data(csv_path, label_col='status', coord_cols=['a', 'e', 'i']):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # Map label 2 to 1 if needed\n",
    "    df[label_col] = df[label_col].replace(2, 1)\n",
    "    # Extract inputs and labels\n",
    "    X = torch.tensor(df[coord_cols].values, dtype=torch.float32)\n",
    "    y = torch.tensor(df[label_col].values, dtype=torch.long)\n",
    "    return X, y\n",
    "\n",
    "X , y = load_data(r\"C:\\Users\\User\\Desktop\\PROJECTS\\stage\\project_submession\\combined_dataset.csv\")\n",
    "\n",
    "# # 2. Separate features and labels\n",
    "# X = data[['a', 'e', 'i']].values  # shape (N,3)\n",
    "# y = data['status'].values           # shape (N,)\n",
    "\n",
    "# 3. Train/test split (optional but good practice)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Convert to torch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)  # long for classification\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# 5. Prepare DataLoader (for batching)\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55436ed3",
   "metadata": {},
   "source": [
    "mc dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03247f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------Mc dropout takes (a e i) as an input and gave the classification and the prob using softmax function-------------------------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MCDropoutModel(nn.Module):\n",
    "    def __init__(self, input_dim=3, hidden_dim=64, output_dim=2, dropout_rate=0.5):\n",
    "        super(MCDropoutModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.dropout1 = nn.Dropout(p=dropout_rate)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.dropout2 = nn.Dropout(p=dropout_rate)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)  # output_dim=2 for binary classification (logits)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)  # dropout always active during both training and inference for MC Dropout\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)       # raw logits (before softmax)\n",
    "        return x\n",
    "\n",
    "    def predict_mc_dropout(self, x, n_samples=100):\n",
    "       self.train()  # dropout active\n",
    "       preds = []\n",
    "       for _ in range(n_samples):\n",
    "           logits = self.forward(x)  # shape: (batch_size, output_dim)\n",
    "           prob = torch.softmax(logits, dim=1)  # shape: (batch_size, output_dim)\n",
    "           preds.append(prob.unsqueeze(0))  # add sample dim at dim 0\n",
    "       preds = torch.cat(preds, dim=0)  # shape: (n_samples, batch_size, output_dim)\n",
    "       return preds\n",
    "\n",
    "\n",
    "# Instantiate model\n",
    "model = MCDropoutModel(input_dim=3, hidden_dim=64, output_dim=2, dropout_rate=0.5)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fecae99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Loss: 1.6611\n",
      "Epoch 2/50 - Loss: 0.7325\n",
      "Epoch 3/50 - Loss: 0.5873\n",
      "Epoch 4/50 - Loss: 0.5229\n",
      "Epoch 5/50 - Loss: 0.4829\n",
      "Epoch 6/50 - Loss: 0.4470\n",
      "Epoch 7/50 - Loss: 0.4073\n",
      "Epoch 8/50 - Loss: 0.3829\n",
      "Epoch 9/50 - Loss: 0.3487\n",
      "Epoch 10/50 - Loss: 0.3275\n",
      "Epoch 11/50 - Loss: 0.3021\n",
      "Epoch 12/50 - Loss: 0.2753\n",
      "Epoch 13/50 - Loss: 0.2611\n",
      "Epoch 14/50 - Loss: 0.2343\n",
      "Epoch 15/50 - Loss: 0.2189\n",
      "Epoch 16/50 - Loss: 0.2089\n",
      "Epoch 17/50 - Loss: 0.1940\n",
      "Epoch 18/50 - Loss: 0.1787\n",
      "Epoch 19/50 - Loss: 0.1753\n",
      "Epoch 20/50 - Loss: 0.1750\n",
      "Epoch 21/50 - Loss: 0.1615\n",
      "Epoch 22/50 - Loss: 0.1466\n",
      "Epoch 23/50 - Loss: 0.1478\n",
      "Epoch 24/50 - Loss: 0.1401\n",
      "Epoch 25/50 - Loss: 0.1283\n",
      "Epoch 26/50 - Loss: 0.1250\n",
      "Epoch 27/50 - Loss: 0.1292\n",
      "Epoch 28/50 - Loss: 0.1222\n",
      "Epoch 29/50 - Loss: 0.1277\n",
      "Epoch 30/50 - Loss: 0.1145\n",
      "Epoch 31/50 - Loss: 0.1165\n",
      "Epoch 32/50 - Loss: 0.1166\n",
      "Epoch 33/50 - Loss: 0.1019\n",
      "Epoch 34/50 - Loss: 0.1096\n",
      "Epoch 35/50 - Loss: 0.1036\n",
      "Epoch 36/50 - Loss: 0.0977\n",
      "Epoch 37/50 - Loss: 0.1008\n",
      "Epoch 38/50 - Loss: 0.1028\n",
      "Epoch 39/50 - Loss: 0.1072\n",
      "Epoch 40/50 - Loss: 0.0988\n",
      "Epoch 41/50 - Loss: 0.0952\n",
      "Epoch 42/50 - Loss: 0.0955\n",
      "Epoch 43/50 - Loss: 0.0863\n",
      "Epoch 44/50 - Loss: 0.0927\n",
      "Epoch 45/50 - Loss: 0.0928\n",
      "Epoch 46/50 - Loss: 0.0902\n",
      "Epoch 47/50 - Loss: 0.0918\n",
      "Epoch 48/50 - Loss: 0.0882\n",
      "Epoch 49/50 - Loss: 0.0847\n",
      "Epoch 50/50 - Loss: 0.0903\n",
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------model training and saving------------------------------------------------------------------------------- \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 50  \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # set model to training mode (dropout active)\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)  # forward pass\n",
    "        loss = criterion(outputs, labels)  # compute loss\n",
    "        \n",
    "        loss.backward()  # backpropagation\n",
    "        optimizer.step()  # update weights\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# save the model weights\n",
    "torch.save(model.state_dict(), \"mc_dropout_BNN.pth\") \n",
    "print(\"Model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09643aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------inference function-----------------------------------------------------------------------------\n",
    "def run_inference_with_uncertainty(model, data_df, device, n_samples=100, filter_threshold=30):\n",
    "    \"\"\"\n",
    "    Runs MC Dropout inference on a filtered DataFrame and returns results with uncertainty measures.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained MCDropoutModel\n",
    "        data_df: Input DataFrame with columns ['a','e','i'] and optionally 'name'\n",
    "        device: torch.device\n",
    "        n_samples: Number of MC Dropout forward passes\n",
    "        filter_threshold: Keep rows where a > threshold\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with predictions and uncertainty statistics\n",
    "    \"\"\"\n",
    "    # Ensure identifier column\n",
    "    if 'name' not in data_df.columns:\n",
    "        data_df = data_df.reset_index().rename(columns={'index': 'name'})\n",
    "\n",
    "    # Filter rows\n",
    "    filtered_data = data_df[data_df['a'] > filter_threshold].copy()\n",
    "    if filtered_data.empty:\n",
    "        print(\"âš ï¸ No rows passed the filter condition.\")\n",
    "        return filtered_data\n",
    "\n",
    "    # Prepare input tensor\n",
    "    X_filtered = filtered_data[['a', 'e', 'i']].values\n",
    "    X_filtered_tensor = torch.tensor(X_filtered, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Run MC Dropout inference\n",
    "    with torch.no_grad():\n",
    "        preds = model.predict_mc_dropout(X_filtered_tensor, n_samples=n_samples)  # (n_samples, batch, num_classes)\n",
    "\n",
    "    # Mean & std of probabilities\n",
    "    mean_preds = preds.mean(dim=0)                                # (batch, num_classes)\n",
    "    std_preds  = preds.std(dim=0, unbiased=False)                  # (batch, num_classes)\n",
    "\n",
    "    # Predicted classes\n",
    "    predicted_classes = torch.argmax(mean_preds, dim=1)            # (batch,)\n",
    "\n",
    "    # Predicted-class probability mean & std\n",
    "    gather_index = predicted_classes.unsqueeze(0).unsqueeze(2).expand(preds.size(0), -1, 1)\n",
    "    preds_for_predclass = preds.gather(dim=2, index=gather_index).squeeze(2)\n",
    "    predicted_prob_mean = preds_for_predclass.mean(dim=0)\n",
    "    predicted_prob_std  = preds_for_predclass.std(dim=0, unbiased=False)\n",
    "\n",
    "    # Predictive entropy\n",
    "    entropy = -torch.sum(mean_preds * torch.log(mean_preds + 1e-12), dim=1)\n",
    "\n",
    "    # Variation ratio (using mode)\n",
    "    mc_pred_classes = torch.argmax(preds, dim=2).cpu().numpy()\n",
    "    from scipy.stats import mode\n",
    "    mode_class, mode_count = mode(mc_pred_classes, axis=0)\n",
    "    variation_ratio = 1 - (mode_count[0] / preds.shape[0])\n",
    "\n",
    "    # Attach results\n",
    "    filtered_data['predicted_class'] = predicted_classes.cpu().numpy()\n",
    "    filtered_data['predicted_prob_mean'] = predicted_prob_mean.cpu().numpy()\n",
    "    filtered_data['predicted_prob_std']  = predicted_prob_std.cpu().numpy()\n",
    "    filtered_data['predictive_entropy']  = entropy.cpu().numpy()\n",
    "    filtered_data['variation_ratio']     = variation_ratio.astype(float)\n",
    "\n",
    "    # Also keep per-class mean & std\n",
    "    num_classes = mean_preds.shape[1]\n",
    "    for c in range(num_classes):\n",
    "        filtered_data[f'prob_mean_c{c}'] = mean_preds[:, c].cpu().numpy()\n",
    "        filtered_data[f'prob_std_c{c}']  = std_preds[:, c].cpu().numpy()\n",
    "\n",
    "    return filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "585831e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_inference_results(df, summary_path=\"summary_orbital_predictions.csv\", detailed_path=None):\n",
    "    \"\"\"\n",
    "    Saves inference results DataFrame to CSVs (summary + optional detailed).\n",
    "    \"\"\"\n",
    "    # Summary columns\n",
    "    selected_columns = [\n",
    "        'name', 'a', 'e', 'i',\n",
    "        'predicted_class',\n",
    "        'predicted_prob_mean', 'predicted_prob_std',\n",
    "        'predictive_entropy', 'variation_ratio'\n",
    "    ]\n",
    "    # Include per-class mean & std if present\n",
    "    for col in df.columns:\n",
    "        if col.startswith(\"prob_mean_c\") or col.startswith(\"prob_std_c\"):\n",
    "            selected_columns.append(col)\n",
    "\n",
    "    summary_df = df[selected_columns].copy()\n",
    "    summary_df.to_csv(summary_path, index=False)\n",
    "    print(f\"âœ… Saved summary to '{summary_path}'\")\n",
    "\n",
    "    # Save full DataFrame if requested\n",
    "    if detailed_path:\n",
    "        df.to_csv(detailed_path, index=False)\n",
    "        print(f\"âœ… Saved detailed results to '{detailed_path}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6967f5d1",
   "metadata": {},
   "source": [
    "Now after having our model trained and inference function ready we can proceed with our MPC data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63e2c371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved summary to 'MC_Dropout_Inference.csv'\n",
      "âœ… Saved detailed results to 'MC_dropout_Inference_detailed.csv'\n"
     ]
    }
   ],
   "source": [
    "# Load test CSV\n",
    "test_data = pd.read_csv(r\"C:\\Users\\User\\Desktop\\PROJECTS\\stage\\converted_data.csv\")\n",
    "\n",
    "# Run inference\n",
    "results_df = run_inference_with_uncertainty(model, test_data, device, n_samples=100, filter_threshold=30)\n",
    "\n",
    "# Save CSVs\n",
    "if not results_df.empty:\n",
    "    save_inference_results(results_df,\n",
    "                           summary_path=\"MC_Dropout_Inference.csv\",\n",
    "                           detailed_path=\"MC_dropout_Inference_detailed.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7391a574",
   "metadata": {},
   "source": [
    "We can also analyse our model performance using the test_loader data from the synthetic rebound data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21ddc0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Test Loss: 0.1233 | Test Accuracy: 93.26%\n"
     ]
    }
   ],
   "source": [
    "# --- Evaluate model on held-out test data (20%) ---\n",
    "model.eval()  # set to eval mode (dropout OFF for deterministic evaluation)\n",
    "\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)  # logits\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Average loss and accuracy\n",
    "test_loss = test_loss / len(test_loader.dataset)\n",
    "test_accuracy = 100 * correct / total\n",
    "\n",
    "print(f\"ðŸ“Š Test Loss: {test_loss:.4f} | Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c16baace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved summary to 'test_summary_predictions.csv'\n",
      "âœ… Saved detailed results to 'test_detailed_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "# --- Uncertainty analysis on test set (20%) ---\n",
    "# Collect test inputs and labels from test_loader\n",
    "import numpy as np \n",
    "all_inputs = []\n",
    "all_labels = []\n",
    "\n",
    "for inputs, labels in test_loader:\n",
    "    all_inputs.append(inputs.cpu().numpy())\n",
    "    all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "X_test = np.vstack(all_inputs)\n",
    "y_test = np.hstack(all_labels)\n",
    "\n",
    "# Put into DataFrame\n",
    "test_df = pd.DataFrame(X_test, columns=['a', 'e', 'i'])\n",
    "test_df['true_label'] = y_test\n",
    "\n",
    "# Run inference with MC Dropout (keep all test samples, no filtering)\n",
    "results_test_df = run_inference_with_uncertainty(\n",
    "    model, test_df, device, n_samples=100, filter_threshold=-np.inf\n",
    ")\n",
    "\n",
    "# Save results\n",
    "save_inference_results(\n",
    "    results_test_df,\n",
    "    summary_path=\"test_summary_predictions.csv\",\n",
    "    detailed_path=\"test_detailed_predictions.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a0ee51",
   "metadata": {},
   "source": [
    "Now we move forward testing the bayes by back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0ad935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "# ---- Bayesian Linear Layer ----\n",
    "class BayesianLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, prior_sigma=0.1):\n",
    "        super(BayesianLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "        # Mean & rho (to compute std via softplus)\n",
    "        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features).uniform_(-0.2, 0.2))\n",
    "        self.weight_rho = nn.Parameter(torch.Tensor(out_features, in_features).uniform_(-5, -4))\n",
    "\n",
    "        self.bias_mu = nn.Parameter(torch.Tensor(out_features).uniform_(-0.2, 0.2))\n",
    "        self.bias_rho = nn.Parameter(torch.Tensor(out_features).uniform_(-5, -4))\n",
    "\n",
    "        # Prior\n",
    "        self.prior_sigma = prior_sigma\n",
    "        self.prior = torch.distributions.Normal(0, prior_sigma)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Compute std from rho\n",
    "        weight_sigma = torch.log1p(torch.exp(self.weight_rho))\n",
    "        bias_sigma = torch.log1p(torch.exp(self.bias_rho))\n",
    "\n",
    "        # Sample weights & bias using reparameterization\n",
    "        weight_eps = torch.randn_like(weight_sigma)\n",
    "        bias_eps = torch.randn_like(bias_sigma)\n",
    "\n",
    "        weight = self.weight_mu + weight_sigma * weight_eps\n",
    "        bias = self.bias_mu + bias_sigma * bias_eps\n",
    "\n",
    "        return F.linear(x, weight, bias)\n",
    "\n",
    "# ---- BBB Neural Network ----\n",
    "class BBBModel(nn.Module):\n",
    "    def __init__(self, input_dim=3, hidden_dim=64, output_dim=2):\n",
    "        super(BBBModel, self).__init__()\n",
    "        self.blinear1 = BayesianLinear(input_dim, hidden_dim)\n",
    "        self.blinear2 = BayesianLinear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.blinear1(x))\n",
    "        return self.blinear2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1de0d42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "# ---- Bayesian Linear Layer ----\n",
    "class BayesianLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, prior_sigma=0.1):\n",
    "        super(BayesianLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "        # Mean & rho (to compute std via softplus)\n",
    "        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features).uniform_(-0.2, 0.2))\n",
    "        self.weight_rho = nn.Parameter(torch.Tensor(out_features, in_features).uniform_(-5, -4))\n",
    "\n",
    "        self.bias_mu = nn.Parameter(torch.Tensor(out_features).uniform_(-0.2, 0.2))\n",
    "        self.bias_rho = nn.Parameter(torch.Tensor(out_features).uniform_(-5, -4))\n",
    "\n",
    "        # Prior\n",
    "        self.prior_sigma = prior_sigma\n",
    "        self.prior = torch.distributions.Normal(0, prior_sigma)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Compute std from rho\n",
    "        weight_sigma = torch.log1p(torch.exp(self.weight_rho))\n",
    "        bias_sigma = torch.log1p(torch.exp(self.bias_rho))\n",
    "\n",
    "        # Sample weights & bias using reparameterization\n",
    "        weight_eps = torch.randn_like(weight_sigma)\n",
    "        bias_eps = torch.randn_like(bias_sigma)\n",
    "\n",
    "        weight = self.weight_mu + weight_sigma * weight_eps\n",
    "        bias = self.bias_mu + bias_sigma * bias_eps\n",
    "\n",
    "        return F.linear(x, weight, bias)\n",
    "\n",
    "# ---- BBB Neural Network ----\n",
    "class BBBModel(nn.Module):\n",
    "    def __init__(self, input_dim=3, hidden_dim=64, output_dim=2):\n",
    "        super(BBBModel, self).__init__()\n",
    "        self.blinear1 = BayesianLinear(input_dim, hidden_dim)\n",
    "        self.blinear2 = BayesianLinear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.blinear1(x))\n",
    "        return self.blinear2(x) \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train_bbb(model, train_loader, device, n_epochs=50, lr=1e-3):\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "\n",
    "            # Negative log-likelihood\n",
    "            loss = F.cross_entropy(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs} - Loss: {total_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cb1d21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def run_bbb_inference(model, data_df, device, n_samples=100, filter_threshold=-np.inf):\n",
    "    model.eval()\n",
    "    results = []\n",
    "\n",
    "    X = torch.tensor(data_df[['a', 'e', 'i']].values, dtype=torch.float32).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx in range(len(X)):\n",
    "            preds = []\n",
    "            for _ in range(n_samples):\n",
    "                outputs = model(X[idx].unsqueeze(0))\n",
    "                probs = F.softmax(outputs, dim=1).cpu().numpy()[0]\n",
    "                preds.append(probs)\n",
    "\n",
    "            preds = np.array(preds)\n",
    "            mean_probs = preds.mean(axis=0)\n",
    "            std_probs = preds.std(axis=0)\n",
    "\n",
    "            predicted_class = mean_probs.argmax()\n",
    "            confidence = mean_probs[predicted_class]\n",
    "            entropy = -np.sum(mean_probs * np.log(mean_probs + 1e-10))\n",
    "            variation_ratio = 1 - (np.bincount(preds.argmax(axis=1), minlength=mean_probs.shape[0]).max() / n_samples)\n",
    "\n",
    "            # Apply filtering if required\n",
    "            if confidence >= filter_threshold:\n",
    "                results.append({\n",
    "                   \"sample_index\": idx,\n",
    "                    \"predicted_class\": predicted_class,\n",
    "                    \"confidence\": confidence,\n",
    "                    \"entropy\": entropy,\n",
    "                    \"variation_ratio\": variation_ratio,\n",
    "                    \"mean_prob\": mean_probs.mean(),   # <- unified name\n",
    "                    \"std_prob\": std_probs.mean(),     # <- unified name\n",
    "                    \"mean_probs\": mean_probs.tolist(), # full distribution\n",
    "                    \"std_probs\": std_probs.tolist()})\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def save_bbb_results(results_df, summary_path=\"bbb_summary.csv\", detailed_path=\"bbb_detailed.csv\"):\n",
    "    summary = results_df.drop(columns=[\"mean_probs\", \"std_probs\"], errors=\"ignore\")\n",
    "    summary.to_csv(summary_path, index=False)\n",
    "    results_df.to_csv(detailed_path, index=False)\n",
    "    print(f\"âœ… Results saved: {summary_path}, {detailed_path}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6772f33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Loss: 0.6908\n",
      "Epoch 2/50 - Loss: 0.5566\n",
      "Epoch 3/50 - Loss: 0.4666\n",
      "Epoch 4/50 - Loss: 0.3710\n",
      "Epoch 5/50 - Loss: 0.2985\n",
      "Epoch 6/50 - Loss: 0.2966\n",
      "Epoch 7/50 - Loss: 0.2200\n",
      "Epoch 8/50 - Loss: 0.2086\n",
      "Epoch 9/50 - Loss: 0.1800\n",
      "Epoch 10/50 - Loss: 0.1583\n",
      "Epoch 11/50 - Loss: 0.1352\n",
      "Epoch 12/50 - Loss: 0.1422\n",
      "Epoch 13/50 - Loss: 0.1290\n",
      "Epoch 14/50 - Loss: 0.1185\n",
      "Epoch 15/50 - Loss: 0.1217\n",
      "Epoch 16/50 - Loss: 0.1021\n",
      "Epoch 17/50 - Loss: 0.1065\n",
      "Epoch 18/50 - Loss: 0.1054\n",
      "Epoch 19/50 - Loss: 0.0977\n",
      "Epoch 20/50 - Loss: 0.1008\n",
      "Epoch 21/50 - Loss: 0.0929\n",
      "Epoch 22/50 - Loss: 0.0891\n",
      "Epoch 23/50 - Loss: 0.0844\n",
      "Epoch 24/50 - Loss: 0.0777\n",
      "Epoch 25/50 - Loss: 0.0962\n",
      "Epoch 26/50 - Loss: 0.0778\n",
      "Epoch 27/50 - Loss: 0.0812\n",
      "Epoch 28/50 - Loss: 0.0895\n",
      "Epoch 29/50 - Loss: 0.0778\n",
      "Epoch 30/50 - Loss: 0.0722\n",
      "Epoch 31/50 - Loss: 0.0769\n",
      "Epoch 32/50 - Loss: 0.0772\n",
      "Epoch 33/50 - Loss: 0.0737\n",
      "Epoch 34/50 - Loss: 0.0735\n",
      "Epoch 35/50 - Loss: 0.0758\n",
      "Epoch 36/50 - Loss: 0.0843\n",
      "Epoch 37/50 - Loss: 0.0682\n",
      "Epoch 38/50 - Loss: 0.0735\n",
      "Epoch 39/50 - Loss: 0.0765\n",
      "Epoch 40/50 - Loss: 0.0792\n",
      "Epoch 41/50 - Loss: 0.0780\n",
      "Epoch 42/50 - Loss: 0.0834\n",
      "Epoch 43/50 - Loss: 0.0746\n",
      "Epoch 44/50 - Loss: 0.0782\n",
      "Epoch 45/50 - Loss: 0.0639\n",
      "Epoch 46/50 - Loss: 0.0678\n",
      "Epoch 47/50 - Loss: 0.0696\n",
      "Epoch 48/50 - Loss: 0.0638\n",
      "Epoch 49/50 - Loss: 0.0685\n",
      "Epoch 50/50 - Loss: 0.0633\n"
     ]
    }
   ],
   "source": [
    "# === Usage on MPC orbital data with filtering ===\n",
    "import pandas as pd\n",
    "import torch\n",
    "# Load MPC orbital data\n",
    "mpc_data = pd.read_csv(r\"C:\\Users\\User\\Desktop\\PROJECTS\\stage\\project_submession\\converted_data.csv\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BBBModel(input_dim=3, hidden_dim=64, output_dim=2)\n",
    "trained_model = train_bbb(model, train_loader, device, n_epochs=50, lr=1e-3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23369a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Results saved: bbb_summary_mpc.csv, bbb_detailed_mpc.csv\n",
      "âœ… BBB inference complete with filtering. Saved to 'bbb_summary_mpc.csv' and 'bbb_detailed_mpc.csv'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# Run BBB inference (with n_samples MC forward passes)\n",
    "results_df = run_bbb_inference(\n",
    "    model,\n",
    "    filtered_mpc_data,\n",
    "    device,\n",
    "    n_samples=100,           # number of stochastic forward passes\n",
    "    filter_threshold=-np.inf \n",
    ")\n",
    "\n",
    "# Merge results back with orbital parameters\n",
    "merged_results = pd.concat([filtered_mpc_data.reset_index(drop=True), results_df], axis=1)\n",
    "\n",
    "# Save results (both summary & detailed versions)\n",
    "save_bbb_results(\n",
    "    merged_results,\n",
    "    summary_path=\"bbb_summary_mpc.csv\",\n",
    "    detailed_path=\"bbb_detailed_mpc.csv\"\n",
    ")\n",
    "\n",
    "print(\"âœ… BBB inference complete with filtering. Saved to 'bbb_summary_mpc.csv' and 'bbb_detailed_mpc.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d76d0287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Test Accuracy: 0.9326\n",
      "âœ… Test NLL: 0.1233\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------a small evaluation ----------------------------------------------\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_bbb(model, X_test_tensor, y_test_tensor, device, n_samples=50):\n",
    "    model.eval()\n",
    "    X_test_tensor, y_test_tensor = X_test_tensor.to(device), y_test_tensor.to(device)\n",
    "\n",
    "    all_mean_preds = []\n",
    "    all_true = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx in range(len(X_test_tensor)):\n",
    "            x = X_test_tensor[idx].unsqueeze(0)\n",
    "            preds = []\n",
    "            for _ in range(n_samples):\n",
    "                logits = model(x)\n",
    "                probs = F.softmax(logits, dim=1)\n",
    "                preds.append(probs.cpu().numpy()[0])\n",
    "\n",
    "            preds = np.array(preds)\n",
    "            mean_probs = preds.mean(axis=0)\n",
    "\n",
    "            all_mean_preds.append(mean_probs)\n",
    "            all_true.append(y_test_tensor[idx].item())\n",
    "\n",
    "    all_mean_preds = np.array(all_mean_preds)\n",
    "    all_true = np.array(all_true)\n",
    "\n",
    "    # Predicted classes\n",
    "    predicted_classes = all_mean_preds.argmax(axis=1)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = (predicted_classes == all_true).mean()\n",
    "\n",
    "    # Negative log-likelihood\n",
    "    nll = -np.mean([np.log(all_mean_preds[i, all_true[i]] + 1e-12) for i in range(len(all_true))])\n",
    "\n",
    "    print(f\"âœ… Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"âœ… Test NLL: {nll:.4f}\")\n",
    "\n",
    "    return accuracy, nll, predicted_classes, all_mean_preds, all_true\n",
    "\n",
    "# Run evaluation\n",
    "accuracy, nll, preds, probs, labels = evaluate_bbb(model, X_test_tensor, y_test_tensor, device, n_samples=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a02a363b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Evaluation complete. Test accuracy: 0.9326\n",
      "âœ… Results saved to: bbb_summary_test.csv (summary), bbb_detailed_test.csv (detailed)\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------this cell is to save prediction of the splitted test data (synthetic)\n",
    "# === Evaluate BBB model on test split + save inference results ===\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "\n",
    "def evaluate_and_save_bbb_test(model, X_test_tensor, y_test_tensor, device, n_samples=100,\n",
    "                               summary_path=\"bbb_summary_test.csv\",\n",
    "                               detailed_path=\"bbb_detailed_test.csv\"):\n",
    "    model.eval()\n",
    "    X_test_tensor, y_test_tensor = X_test_tensor.to(device), y_test_tensor.to(device)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx in range(len(X_test_tensor)):\n",
    "            x = X_test_tensor[idx].unsqueeze(0)\n",
    "            preds_mc = []\n",
    "            for _ in range(n_samples):\n",
    "                logits = model(x)\n",
    "                probs = F.softmax(logits, dim=1)\n",
    "                preds_mc.append(probs.cpu().numpy()[0])\n",
    "            \n",
    "            preds_mc = np.array(preds_mc)\n",
    "            mean_probs = preds_mc.mean(axis=0)\n",
    "            std_probs = preds_mc.std(axis=0)\n",
    "            \n",
    "            predicted_class = mean_probs.argmax()\n",
    "            confidence = mean_probs[predicted_class]\n",
    "            entropy = -np.sum(mean_probs * np.log(mean_probs + 1e-12))\n",
    "            variation_ratio = 1 - (np.bincount(preds_mc.argmax(axis=1), minlength=mean_probs.shape[0]).max() / n_samples)\n",
    "            \n",
    "            results.append({\n",
    "                \"sample_index\": idx,\n",
    "                \"true_label\": y_test_tensor[idx].item(),\n",
    "                \"predicted_class\": predicted_class,\n",
    "                \"confidence\": confidence,\n",
    "                \"entropy\": entropy,\n",
    "                \"variation_ratio\": variation_ratio,\n",
    "                \"mean_probs\": mean_probs.tolist(),\n",
    "                \"std_probs\": std_probs.tolist()\n",
    "            })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Save summary (without per-class mean/std lists)\n",
    "    summary_df = results_df.drop(columns=[\"mean_probs\", \"std_probs\"], errors=\"ignore\")\n",
    "    summary_df.to_csv(summary_path, index=False)\n",
    "    results_df.to_csv(detailed_path, index=False)\n",
    "    \n",
    "    print(f\"âœ… Evaluation complete. Test accuracy: {(summary_df['predicted_class'] == summary_df['true_label']).mean():.4f}\")\n",
    "    print(f\"âœ… Results saved to: {summary_path} (summary), {detailed_path} (detailed)\")\n",
    "\n",
    "    return summary_df, results_df\n",
    "\n",
    "# Run evaluation + save\n",
    "summary_df, detailed_df = evaluate_and_save_bbb_test(model, X_test_tensor, y_test_tensor, device,\n",
    "                                                     n_samples=100,\n",
    "                                                     summary_path=\"bbb_summary_test.csv\",\n",
    "                                                     detailed_path=\"bbb_detailed_test.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
